corpus = Corpus(VectorSource(tweets$Tweet))
str(corpus)
corpus
strwrap(corpus[[1]])
strwrap(tweets$Tweet[1])
corpus = tm_map(corpus, tolower)
strwrap(corpus[[1]])
corpus = tm_map(corpus, removePunctuation) # remove punctuation
strwrap(corpus[[1]])
corpus = tm_map(corpus, removeWords, stopwords("english"))
strwrap(corpus[[1]])
dtm = DocumentTermMatrix(corpus)
dtm
allTweets = = as.data.frame(as.matrix(dtm))
allTweets = as.data.frame(as.matrix(dtm))
str(allTweets)
install.packages("wordcloud")
library(wordcloud)
str(allTweets)
allTweets
?wordcloud
rownames(allTweets)
colnames(allTweets)
rownames(allTweets)
colnames(allTweets)
str(allTweets)
colSums(allTweets)
rowSums(allTweets)
sum(allTweets)
?wordcloud
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq=3)
wordcloud(colnames(allTweets), colSums(allTweets), random.color=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), colors="black",ordered.colors=FALSE)
wordcloud(colnames(allTweets), colSums(allTweets), colors="red",ordered.colors=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), colors="red")
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", scale=c(4,0.5))
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", scale=c(2,0.25))
tweets = read.csv("tweets.csv", stringsAsFactors = FALSE)
str(tweets)
strwrap(tweets$Tweet[1])
tweets$Avg[1]
corpus = Corpus(VectorSource(tweets$Tweet))
corpus
strwrap(corpus[[1]])
corpus = tm_map(corpus, tolower)
strwrap(corpus[[1]])
corpus = tm_map(corpus, removePunctuation)
strwrap(corpus[[1]])
corpus = tm_map(corpus, tolower)
strwrap(corpus[[1]])
corpus = Corpus(VectorSource(tweets$Tweet))
corpus
strwrap(corpus[[1]])
corpus = tm_map(corpus, tolower)
strwrap(corpus[[1]]) # changed to lower case
corpus = tm_map(corpus, removePunctuation) # remove punctuation
strwrap(corpus[[1]])
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english"))) #remove stop words + apple
strwrap(corpus[[1]])
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation) # remove punctuation
corpus = tm_map(corpus, removeWords, stopwords("english"))
strwrap(corpus[[1]])
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english"))) #remove stop words + apple
strwrap(corpus[[1]])
dtm = DocumentTermMatrix(corpus) #document-term matrix out of the corpus
dtm
allTweets = as.data.frame(as.matrix(dtm))
str(allTweets)
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", scale=c(4,0.5))
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", scale=c(2,0.25))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2,0.25))
?wordcloud
str(allTweets)
tweets$Avg
allTweets$Avg = tweets$Avg
wordcloud(colnames(allTweets), allTweets$Avg <= -1, colors="red", scale=c(4,0.5))
allTweets$Avg <= -1
wordcloud(colnames(allTweets), colSums(allTweets$Avg <= -1), colors="red", scale=c(4,0.5))
negativeTweets = subset(allTweets, tweets$Avg <= -1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets))
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", min.freq=3)
wordcloud(colnames(allTweets), colSums(allTweets), colors="red")
wordcloud(colnames(allTweets), colSums(allTweets), colors="red", random.order=FALSE)
wordcloud(colnames(negativeTweets), colSums(negativeTweets, random.order=F))
wordcloud(colnames(negativeTweets), colSums(negativeTweets, random.order=FALSE))
wordcloud(colnames(negativeTweets), colSums(negativeTweets), random.order=FALSE))
wordcloud(colnames(negativeTweets), colSums(negativeTweets), random.order=FALSE)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=50)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=20)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=10)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=1)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=0)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=0.5)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=0.2)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=.1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), random.order=FALSE, rot.per=.1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), rot.per=.1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), rot.per=.2)
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, rot.per=.2)
wordcloud(colnames(allTweets), colSums(allTweets), rot.per=.2)
wordcloud(colnames(allTweets), colSums(allTweets), rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), rot.per=.5, ordered.colors=TRUE)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), ordered.colors=TRUE)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), color="red", ordered.colors=TRUE)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), color="red", ordered.colors=TRUE, scale=c(2,0.25))
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(RColorBrewer)
library(wordcloud)
brewer.pal()
display.brewer.pal()
display.brewer.all()
display.brewer.all()
display.brewer.all()
wordcloud(colnames(negativeTweets), colSums(negativeTweets), colors=brewer.pal(9, "Blues"), ordered.colors=TRUE, scale=c(2,0.25))
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues"), rot.per=.5, ordered.colors=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-5, -6, -7, -8, -9)], rot.per=.5, ordered.colors=TRUE)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-1, -2, -3, -4)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-5, -6, -7, -8, -9)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-5, -6, -7, -8, rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues"), rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues"), rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-1, -2, -3, -4)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(1, 2, 3, 4)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(5, 6, 7, 8, 9)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-5, -6, -7, -8, -9)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-1, -2, -3, -4)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(1, 2, 3, 4)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(5, 6, 7, 8, 9)], rot.per=.5)
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[c(-1, -2, -3, -4)], rot.per=.5)
train = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/train.csv")
test = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/test.csv")
library(caTools)
library(rpart)
library(rpart.plot)
library(caret)
split = sample.split(train$Happy, SplitRatio= 0.7)
splitTrain = subset(train, split == TRUE)
splitTest = subset(train, split == FALSE)
distances = dist(splitTrain[3:110], method="euclidean")
clusterHappiness = hclust(distances, method="ward.D")
plot(clus)
plot(clusterHappiness)
clusterGroups = cutree(clusterHappiness, k = 6)
tapply(splitTrain$Income, clusterGroups, mean)
clusterGroups
splitTrain$Income
str(splitTrain)
tapply(splitTrain$Q99982, clusterGroups, mean)
splitTrain$Income
str(splitTrain)
rect.hclust(clusterHappiness, k=6, border="red")
rect.hclust(clusterHappiness, k=7, border="red")
clusterGroups = cutree(clusterHappiness, k = 7)
rect.hclust(clusterHappiness, k=7, border="red")
clusterGroups
tapply(splitTrain, clusterGroups, mean)
tapply(splitTrain[3:110], clusterGroups, mean)
train_new = train
train_new$Age = 2014 - train_new$YOB
train_new$Age
summary(train_new$YOB)
summary(train_new$Age)
train_new$Gender.empty = as.integer(train_new$Gender == "")
summary(train_new$Gender.empty)
table(train_new$Gender)
table(train_new$Gender.empty)
train_new$Gender.female = as.integer(train_new$Gender == "Female")
train_new$Gender.male = as.integer(train_new$Gender == "Male")
table(train_new$Gender)
table(train_new$Gender.empty)
table(train_new$Gender.female)
table(train_new$Gender.male)
train_new$Gender.empty = as.integer(train_new$Gender == "" & train_new$Gender != "Male" & train_new$Gender != "Female")
table(train_new$Gender)
table(train_new$Gender.empty)
table(train_new$Gender.male)
table(train_new$Gender.female)
train_new = train_new[train_new$Gender != ""]
table(train_new$Gender)
train_new = train_new[train_new$Gender != ""]
train_new$Gender = train_new[train_new$Gender != ""]
table(train_new$Gender)
install.packages("gdata")
library(gdata)
train = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/train.csv", stringsAsFactors=FALSE)
test = read.csv("C:/Users/Fahad/Documents/R Projects/edXCompetition/Data/test.csv", stringsAsFactors=FALSE)
train.with.NAs = train
test.with.NAs = test
str(train.with.NAs)
train.with.NAs[train.with.NAs == ""] = NA
test.with.NAs[test.with.NAs == ""] = NA
str(train.with.NAs)
str(test.with.NAs)
train.with.NAs[,grep(pattern="^Q1",colnames(train.with.NAs))] = lapply(train.with.NAs[,grep(pattern="^Q1",colnames(train.with.NAs))],as.factor)
train.with.NAs[,grep(pattern="^Q9",colnames(train.with.NAs))] = lapply(train.with.NAs[,grep(pattern="^Q9",colnames(train.with.NAs))],as.factor)
test.with.NAs[,grep(pattern="^Q9",colnames(test.with.NAs))] = lapply(test.with.NAs[,grep(pattern="^Q9",colnames(test.with.NAs))],as.factor)
test.with.NAs[,grep(pattern="^Q1",colnames(test.with.NAs))] = lapply(test.with.NAs[,grep(pattern="^Q1",colnames(test.with.NAs))],as.factor)
train.with.NAs$Gender = as.factor(train.with.NAs$Gender)
test.with.NAs$Gender = as.factor(test.with.NAs$Gender)
train.with.NAs$Income = as.factor(train.with.NAs$Income)
test.with.NAs$Income = as.factor(test.with.NAs$Income)
train.with.NAs$HouseholdStatus = as.factor(train.with.NAs$HouseholdStatus)
test.with.NAs$HouseholdStatus = as.factor(test.with.NAs$HouseholdStatus)
train.with.NAs$EducationLevel = as.factor(train.with.NAs$EducationLevel)
test.with.NAs$EducationLevel = as.factor(test.with.NAs$EducationLevel)
train.with.NAs$Party = as.factor(train.with.NAs$Party)
test.with.NAs$Party = as.factor(test.with.NAs$Party)
str(train.with.NAs)
str(test.with.NAs)
train.with.NAs$Age = 2014 - train.with.NAs$YOB
test.with.NAs$Age = 2014 - test.with.NAs$YOB
class(train.with.NAs$YOB)
class(train.with.NAs$Age)
train.with.NAs$Age = as.integer(train.with.NAs$Age)
test.with.NAs$Age = as.integer(test.with.NAs$Age)
class(train.with.NAs$Age)
summary(train.with.NAs)
summary(test.with.NAs)
library(mice)
imputed_train = read.csv("imputed.csv")
imputed_test = read.csv("imputedtest.csv")
str(imputed_test)
summary(imputed_test)
str(imputed_train)
summary(imputed_train)
library(caTools)
class(imputed_train$Happy)
imputed_train$Happy = as.factor(imputed_train$Happy)
split = sample.split(imputed_train$Happy, SplitRatio= 0.7)
splitTrain = subset(imputed_train, split == TRUE)
splitTest = subset(imputed_train, split == FALSE)
table(splitTrain$Happy)
1823/(1410+1823)
logRegModel = glm(Happy ~. -UserID -YOB - Q96024 -Q100562 - Q99480 -Q118117 -Q119851 -Q109244 -Q123464 - Q124122 -Q112478 -Q113583 -Q112270 -Q111580 -Q100010 -Q118892 -Q114961 -Q115611 -Q120978 -Q120472 -Q115899 -Q119650 -Q106993 -Q105840 - Q105655 -Q99716 -Q102089 -Q118232 -Q108855 -Q114517 -Q122770 -Q98059 -Q106042 -Q115602 -Q112512 -Q115777 -Q116448 -Q116797 -Q114152 -Q120379 -Q120650 -Q113181 -Q111848 -Q116601 -Q106388 -Q98197 -Q98578 -Q113992 -Q108754 -Q117186, data=splitTrain, family=binomial)
summary(logRegModel)
logRegPred = predict(logRegModel, newdata=splitTest, type="response")
table(splitTest$Happy, logRegPred >0.5)
(323+605)/nrow(splitTest)
class(splitTrain$Happy)
HappinessForest = randomForest(Happy ~ . -UserID -YOB, data=splitTrain)
library(randomForest)
HappinessForest = randomForest(Happy ~ . -UserID -YOB, data=splitTrain)
print(HappinessForest)
PredictForest = predict(HappinessForest, newdata=splitTest)
table(splitTest$Happy, PredictForest)
(295+635)/nrow(splitTest)
HappinessForest2 = randomForest(Happy ~ . -UserID -YOB - Q96024 -Q100562 - Q99480 -Q118117 -Q119851 -Q109244 -Q123464 - Q124122 -Q112478 -Q113583 -Q112270 -Q111580 -Q100010 -Q118892 -Q114961 -Q115611 -Q120978 -Q120472 -Q115899 -Q119650 -Q106993 -Q105840 - Q105655 -Q99716 -Q102089 -Q118232 -Q108855 -Q114517 -Q122770 -Q98059 -Q106042 -Q115602 -Q112512 -Q115777 -Q116448 -Q116797 -Q114152 -Q120379 -Q120650 -Q113181 -Q111848 -Q116601 -Q106388 -Q98197 -Q98578 -Q113992 -Q108754 -Q117186, data=splitTrain)
print(HappinessForest2)
PredictForest2 = predict(HappinessForest2, newdata=splitTest)
table(splitTest$Happy, PredictForest2)
(298+623)/nrow(splitTest)
class(imputed_train$Happy)
HappinessForestKaggle = randomForest(Happy ~ ., data=imputed_train)
print(HappinessForestKaggle)
PredictForestKaggle = predict(HappinessForestKaggle, newdata=imputed_test, type="prob")
PredictForestKaggle
PredictForestKaggle[,2]
submission = cbind(UserID=imputed_test$UserID, Probability1=PredictForestKaggle[,2])
View(submission)
write.table(submission,file="submission13.csv",sep=",",row.names=F)
library(ggplot2)
library(caTools)
ggplot(train_numeric, aes(x=Happy)) + geom_histogram(binwidth=5, color="blue") + facet_grid( . ~ Gender)
ggplot(imputed_train, aes(x=Happy)) + geom_histogram(binwidth=5, color="blue") + facet_grid( . ~ Gender)
ggplot(imputed_train, aes(x=Happy)) + geom_histogram(binwidth=5, color="blue")
ggplot(imputed_train, aes(x=Happy)) + geom_histogram()
hist(imputed_train$Happy)
imputed_train$Happy = as.integer(imputed_train$Happy)
hist(imputed_train$Happy)
imputed_train$Happy = as.factor(imputed_train$Happy)
hist(imputed_train$Happy)
ggplot(imputed_train, aes(x=Happy)) + geom_histogram(binwidth=5, color="blue")
limited.splitTrain = splitTrain
limited.splitTest = splitTest
limited.splitTrain$Happy = NULL
limited.splitTest$Happy = NULL
summary(limited.splitTrain)
str(limited.splitTrain)
km = kmeans(limited.splitTrain, centers=4)
km
km = kmeans(limited.splitTrain, centers=5)
is.na(limited.splitTrain)
summary(limited.splitTrain)
km = kmeans(limited.splitTrain, centers=5)
limited.splitTrain$UserID = NULL
limited.splitTest$UserID = NULL
km = kmeans(limited.splitTrain, 5)
preproc = preProcess(limited.splitTrain)
library(caret)
preproc = preProcess(limited.splitTrain)
str(limited.splitTrain)
cube = function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
y
y <- if(x < 3) {
NA
} else {
10
}
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
swirl()
library(swirl)
swirl()
1:20
pi:10
15:1
`:`
':'
?':'
?`:`
seq(1,20)
seq(0,10,by=0.5)
my_seq = seq(5,10,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along=my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(c,1c2),each=10)
rep(c(0,1,2),each=10)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
setwd("~/R Projects/Coursera/r-programming-coursera/Code/Assignments")
submit()
submit()
complete <- function(directory, id = 1:332) {
#set the path
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/"
path = c(path,directory)
path = paste(path,collapse="")
#get the file List in that directory
fileList = list.files(path)
#extract the file names and store as numeric for comparison
file.names = as.numeric(sub("\\.csv$","",fileList))
#select files to be imported based on the user input or default
selected.files = fileList[match(id,file.names)]
#import data
Data = lapply(file.path(path,selected.files),read.csv)
#get the complete cases
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
#create a dataframe to return
res = data.frame()
#get the number of complete cases and put it in the result dataframe
for(i in 1:length(completeCases)){
res <- rbind(res, nob=nrow(completeCases[[i]]))
}
#add ID column
res <- cbind(res,id=id)
#remove rownames
rownames(res) <- NULL
#add column names
colnames(res) <- c("nob","id")
#re-arrange column names
res = res[c("id", "nob")]
#return the results dataframe
res
}
complete("specdata",1)
complete("specdata",30:25)
submit()
source("complete.R")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
6
submit()
submit()
complete("specdata",1)
complete("specdata",c(2, 4, 8, 10, 12))
complete("specdata",30:25)
complete("specdata",3)
class(res)
complete <- function(directory, id = 1:332) {
#set the path
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/"
path = c(path,directory)
path = paste(path,collapse="")
#get the file List in that directory
fileList = list.files(path)
#extract the file names and store as numeric for comparison
file.names = as.numeric(sub("\\.csv$","",fileList))
#select files to be imported based on the user input or default
selected.files = fileList[match(id,file.names)]
#import data
Data = lapply(file.path(path,selected.files),read.csv)
#get the complete cases
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
#create a dataframe to return
res = data.frame()
#get the number of complete cases and put it in the result dataframe
for(i in 1:length(completeCases)){
res <- rbind(res, nob=nrow(completeCases[[i]]))
}
#add ID column
res <- cbind(res,id=id)
#remove rownames
rownames(res) <- NULL
#add column names
colnames(res) <- c("nob","id")
#re-arrange column names
res = res[c("id", "nob")]
#return the results dataframe
res
class(res)
}
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
fileList
file.names = as.numeric(sub("\\.csv$","",fileList))
file.names
selected.files = fileList[match(id,file.names)]
selected.files = fileList[match(1,file.names)]
selected.files
Data = lapply(file.path(path,selected.files),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = data.frame()
for(i in 1:length(completeCases)){
res <- rbind(res, nob=nrow(completeCases[[i]]))
}
res <- cbind(res,id=id)
res <- cbind(res,id=1)
rownames(res) <- NULL
colnames(res) <- c("nob","id")
res = res[c("id", "nob")]
res
class(res)
complete("specdata",1)
complete <- function(directory, id = 1:332) {
#set the path
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/"
path = c(path,directory)
path = paste(path,collapse="")
#get the file List in that directory
fileList = list.files(path)
#extract the file names and store as numeric for comparison
file.names = as.numeric(sub("\\.csv$","",fileList))
#select files to be imported based on the user input or default
selected.files = fileList[match(id,file.names)]
#import data
Data = lapply(file.path(path,selected.files),read.csv)
#get the complete cases
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
#create a dataframe to return
res = data.frame()
#get the number of complete cases and put it in the result dataframe
for(i in 1:length(completeCases)){
res <- rbind(res, nob=nrow(completeCases[[i]]))
}
#add ID column
res <- cbind(res,id=id)
#remove rownames
rownames(res) <- NULL
#add column names
colnames(res) <- c("nob","id")
#re-arrange column names
res = res[c("id", "nob")]
#return the results dataframe
res
}
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete("specdata", 3)
source("complete.R")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
6
submit()
submit()
